<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2026-01-16T19:28:54-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">SchmitCodes</title><subtitle>This page is for documenting portfolio projects and blogging about current topics.</subtitle><author><name>Shannon Smith</name><email>ssmit584@charlotte.edu</email></author><entry><title type="html">Data Science, Social Science, and Responsibilities</title><link href="http://localhost:4000/2026/01/16/welcome.html" rel="alternate" type="text/html" title="Data Science, Social Science, and Responsibilities" /><published>2026-01-16T00:00:00-05:00</published><updated>2026-01-16T00:00:00-05:00</updated><id>http://localhost:4000/2026/01/16/welcome</id><content type="html" xml:base="http://localhost:4000/2026/01/16/welcome.html"><![CDATA[<h3 id="why-model-social-topics-and-people">Why model social topics and people?</h3>

<p>As you start diving into data science, you start to find that data is largely generated by people, therefore considering your assumptions and models from a social standpoint can be just as important as looking at the problem from an ethical standpoint. When we model social topics and human behavior, we’re not just crunching numbers. We’re trying to understand patterns in how people live, interact, and make decisions. These models can reveal trends or make predictions that directly affect the people and world around us. The algorithms we create have real-world consequences—they influence hiring decisions, loan approvals, criminal justice outcomes, and countless other aspects of people’s lives. This reality makes it crucial to consider who might be impacted by our work and how.</p>

<h3 id="responsibilities-that-arise-out-of-the-social-context">Responsibilities that arise out of the social context</h3>

<p>When considering the overall responsibility of maintaining an ethical data science workflow, the impending thought of balancing performance versus fairness comes to mind. Essentially, you can manipulate these models to get your desired output instead of unbiased predictions. This tension becomes especially apparent when optimizing for accuracy might amplify existing biases in the training data. A model might perform well statistically while perpetuating discrimination against certain groups, raising difficult questions about what “success” really means.</p>

<h3 id="what-i-want-to-take-away-from-dtsc-2301">What I want to take away from DTSC 2301</h3>

<p>What I’m really hoping to get out of this course is a better framework for thinking about ethical questions. I want to develop practical strategies for identifying potential harms before they occur and learn how to engage stakeholders who might be affected by my work. Overall, I want to learn not just how to build models, but instead build models that attempt to solve real-world problems or answer interesting questions while respecting the dignity and rights of the people represented in the data. At the end of the day, data science is a powerful tool, but we need to use it thoughtfully. I’m looking forward to learning how to do that.</p>]]></content><author><name>Shannon Smith</name><email>ssmit584@charlotte.edu</email></author><summary type="html"><![CDATA[Why model social topics and people?]]></summary></entry></feed>